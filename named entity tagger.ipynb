{
 "metadata": {
  "name": "",
  "signature": "sha256:bc3ce6292433e35efd13ca2d313add2e56e5c540abe9709aa0e3460975d154b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Named Entity Tagger\n",
      "main task is to detect whether the text contain special entity, such as following 7 classes:\n",
      "- location\n",
      "- organization\n",
      "- date\n",
      "- money\n",
      "- person\n",
      "- percent\n",
      "- time\n",
      "\n",
      "Online demo: http://nlp.stanford.edu:8080/ner/process\n",
      "\n",
      "Reference\n",
      "- http://nlp.stanford.edu/software/CRF-NER.shtml"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk \n",
      "# with open('sample.txt', 'r') as f:\n",
      "#     sample = f.read()\n",
      "\n",
      "sample = \"in my own language.\\\n",
      "As a video uploader, this means you can reach\\\n",
      "to people all over the world,\\\n",
      "irrespective of language.\\\n",
      "[Hiroto, Bedhead]\\\n",
      "You can upload multiple tracks like English and French,\\\n",
      "and viewers can choose the track they like.\\\n",
      "[Toliver, Japanese Learner]\\\n",
      "For example, if you enjoy using YouTube in French,\"\n",
      "\n",
      "sentences = nltk.sent_tokenize(sample)\n",
      "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
      "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
      "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
      "\n",
      "def extract_entity_names(t):\n",
      "    entity_names = []\n",
      "\n",
      "    if hasattr(t, 'label') and t.label:\n",
      "        if t.label() == 'NE':\n",
      "            entity_names.append(' '.join([child[0] for child in t]))\n",
      "        else:\n",
      "            for child in t:\n",
      "                entity_names.extend(extract_entity_names(child))\n",
      "\n",
      "    return entity_names\n",
      "\n",
      "entity_names = []\n",
      "for tree in chunked_sentences:\n",
      "    # Print results per sentence\n",
      "    # print extract_entity_names(tree)\n",
      "\n",
      "    entity_names.extend(extract_entity_names(tree))\n",
      "\n",
      "# Print all entity names\n",
      "#print entity_names\n",
      "\n",
      "# Print unique entity names\n",
      "print set(entity_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['Bedhead', 'YouTube', 'French', 'English', 'Hiroto', 'Japanese Learner'])\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Stanford NER\n",
      "\n",
      "Install java 8, download Stanford NER, and set the environment variable first.\n",
      "\n",
      "NLTK just provide an interface of Stanford NER"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tag import StanfordNERTagger\n",
      "\n",
      "st = StanfordNERTagger('/vagrant/stanford-ner-2015-12-09/classifiers/english.muc.7class.distsim.crf.ser.gz', '/vagrant/stanford-ner-2015-12-09/stanford-ner.jar') \n",
      "st.tag('Rami Eid is studying at Stony Brook University in NY'.split()) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "[(u'Rami', u'O'),\n",
        " (u'Eid', u'O'),\n",
        " (u'is', u'O'),\n",
        " (u'studying', u'O'),\n",
        " (u'at', u'O'),\n",
        " (u'Stony', u'ORGANIZATION'),\n",
        " (u'Brook', u'ORGANIZATION'),\n",
        " (u'University', u'ORGANIZATION'),\n",
        " (u'in', u'O'),\n",
        " (u'NY', u'ORGANIZATION')]"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = \"in my own language. \\\n",
      "As a video uploader, this means you can reach\\\n",
      "to people all over the world,\\\n",
      "irrespective of language. \\\n",
      "[Hiroto, Bedhead]\\\n",
      "You can upload multiple tracks like English and French,\\\n",
      "and viewers can choose the track they like. \\\n",
      "[Toliver, Japanese Learner]\\\n",
      "For example, if you enjoy using YouTube in French, 1990, July\"\n",
      "\n",
      "import string\n",
      "from nltk.tokenize import word_tokenize\n",
      "st.tag(word_tokenize(sample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[(u'in', u'O'),\n",
        " (u'my', u'O'),\n",
        " (u'own', u'O'),\n",
        " (u'language', u'O'),\n",
        " (u'.', u'O'),\n",
        " (u'As', u'O'),\n",
        " (u'a', u'O'),\n",
        " (u'video', u'O'),\n",
        " (u'uploader', u'O'),\n",
        " (u',', u'O'),\n",
        " (u'this', u'O'),\n",
        " (u'means', u'O'),\n",
        " (u'you', u'O'),\n",
        " (u'can', u'O'),\n",
        " (u'reachto', u'O'),\n",
        " (u'people', u'O'),\n",
        " (u'all', u'O'),\n",
        " (u'over', u'O'),\n",
        " (u'the', u'O'),\n",
        " (u'world', u'O'),\n",
        " (u',', u'O'),\n",
        " (u'irrespective', u'O'),\n",
        " (u'of', u'O'),\n",
        " (u'language', u'O'),\n",
        " (u'.', u'O'),\n",
        " (u'[', u'O'),\n",
        " (u'Hiroto', u'PERSON'),\n",
        " (u',', u'O'),\n",
        " (u'Bedhead', u'O'),\n",
        " (u']', u'O'),\n",
        " (u'You', u'O'),\n",
        " (u'can', u'O'),\n",
        " (u'upload', u'O'),\n",
        " (u'multiple', u'O'),\n",
        " (u'tracks', u'O'),\n",
        " (u'like', u'O'),\n",
        " (u'English', u'O'),\n",
        " (u'and', u'O'),\n",
        " (u'French', u'O'),\n",
        " (u',', u'O'),\n",
        " (u'and', u'O'),\n",
        " (u'viewers', u'O'),\n",
        " (u'can', u'O'),\n",
        " (u'choose', u'O'),\n",
        " (u'the', u'O'),\n",
        " (u'track', u'O'),\n",
        " (u'they', u'O'),\n",
        " (u'like', u'O'),\n",
        " (u'.', u'O'),\n",
        " (u'[', u'O'),\n",
        " (u'Toliver', u'PERSON'),\n",
        " (u',', u'O'),\n",
        " (u'Japanese', u'O'),\n",
        " (u'Learner', u'O'),\n",
        " (u']', u'O'),\n",
        " (u'For', u'O'),\n",
        " (u'example', u'O'),\n",
        " (u',', u'O'),\n",
        " (u'if', u'O'),\n",
        " (u'you', u'O'),\n",
        " (u'enjoy', u'O'),\n",
        " (u'using', u'O'),\n",
        " (u'YouTube', u'O'),\n",
        " (u'in', u'O'),\n",
        " (u'French', u'O'),\n",
        " (u',', u'O'),\n",
        " (u'1990', u'DATE'),\n",
        " (u',', u'O'),\n",
        " (u'July', u'DATE')]"
       ]
      }
     ],
     "prompt_number": 27
    }
   ],
   "metadata": {}
  }
 ]
}